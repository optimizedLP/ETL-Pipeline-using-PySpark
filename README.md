# ETL Pipeline with PySpark

This project demonstrates the development of an ETL (Extract, Transform, Load) pipeline using PySpark to process a CSV dataset of temperature data. The pipeline performs the following tasks:

## Overview

### ETL Process:
1. **Extract**: Load the dataset from a CSV file.
2. **Transform**: 
   - Clean the data.
   - Handle missing values.
   - Pivot year-wise temperature data for analysis.
3. **Load**: Save the processed data into a new storage format (e.g., Parquet or a database).

---

